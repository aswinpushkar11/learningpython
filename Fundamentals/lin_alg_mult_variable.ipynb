{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "y_train: [460 232 178]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "print('x_train:',x_train)\n",
    "print('y_train:',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (3, 4), X Type:<class 'numpy.ndarray'>)\n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "y Shape: (3,), y Type:<class 'numpy.ndarray'>)\n",
      "[460 232 178]\n"
     ]
    }
   ],
   "source": [
    "# data is stored in numpy array/matrix\n",
    "print(f\"X Shape: {x_train.shape}, X Type:{type(x_train)})\")\n",
    "print(x_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w,b):\n",
    "    #dpt product of w and b\n",
    "    p=np.dot(x,w)+b\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (4,), x_vec value: [2104    5    1   45]\n",
      "f_wb shape (), prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "x_vec=x_train[0,:]\n",
    "x_vec\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "# make a prediction\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the overall cost\n",
    "def compute_cost(X,y,w,b):\n",
    "    m=X.shape[0]\n",
    "    cost=0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i=np.dot(X[i],w)+b\n",
    "        cost+=((f_wb_i-y[i])**2)\n",
    "    cost=cost/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal W : {1.5578904428966628e-12}\n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(x_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal W :',{cost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X,y,w,b):\n",
    "\n",
    "    m,n=X.shape\n",
    "    print('m:',m)\n",
    "    print('n:',n)\n",
    "    #random initialisation of db and dW\n",
    "    dj_db = 0.\n",
    "    dj_dw=np.zeros((n,))\n",
    "\n",
    "    for i in range(m):\n",
    "        err = (np.dot(X[i],w)+b)-y[i]\n",
    "        print(f'error{i}',err)\n",
    "        for j in range(n):\n",
    "            print( f'dj_dw{j}_before', dj_dw[j])\n",
    "            dj_dw[j]=dj_dw[j]+err*X[i,j]\n",
    "            print( f'dj_dw{j}_after', dj_dw[j])\n",
    "            print(f'dj_dw{j}:',dj_dw[j])\n",
    "        print( f'dj_db{i}_before',dj_db)\n",
    "        dj_db +=err\n",
    "        print( f'dj_db{i}_after',dj_db)\n",
    "        print()\n",
    "    dj_dw+=dj_dw/m\n",
    "    dj_db+=dj_db/m\n",
    "    print('dj_db',dj_db)\n",
    "    print('dj_dw',dj_dw)\n",
    "\n",
    "    return dj_dw,dj_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 3\n",
      "n: 4\n",
      "error0 -2.380591695327894e-06\n",
      "dj_dw0_before 0.0\n",
      "dj_dw0_after -0.005008764926969889\n",
      "dj_dw0: -0.005008764926969889\n",
      "dj_dw1_before 0.0\n",
      "dj_dw1_after -1.190295847663947e-05\n",
      "dj_dw1: -1.190295847663947e-05\n",
      "dj_dw2_before 0.0\n",
      "dj_dw2_after -2.380591695327894e-06\n",
      "dj_dw2: -2.380591695327894e-06\n",
      "dj_dw3_before 0.0\n",
      "dj_dw3_after -0.00010712662628975522\n",
      "dj_dw3: -0.00010712662628975522\n",
      "dj_db0_before 0.0\n",
      "dj_db0_after -2.380591695327894e-06\n",
      "\n",
      "error1 -1.6305918961734278e-06\n",
      "dj_dw0_before -0.005008764926969889\n",
      "dj_dw0_after -0.007317683051951462\n",
      "dj_dw0: -0.007317683051951462\n",
      "dj_dw1_before -1.190295847663947e-05\n",
      "dj_dw1_after -1.6794734165159753e-05\n",
      "dj_dw1: -1.6794734165159753e-05\n",
      "dj_dw2_before -2.380591695327894e-06\n",
      "dj_dw2_after -5.6417754876747495e-06\n",
      "dj_dw2: -5.6417754876747495e-06\n",
      "dj_dw3_before -0.00010712662628975522\n",
      "dj_dw3_after -0.00017235030213669233\n",
      "dj_dw3: -0.00017235030213669233\n",
      "dj_db1_before -2.380591695327894e-06\n",
      "dj_db1_after -4.011183591501322e-06\n",
      "\n",
      "error2 -1.0105918590852525e-06\n",
      "dj_dw0_before -0.007317683051951462\n",
      "dj_dw0_after -0.008178707315892098\n",
      "dj_dw0: -0.008178707315892098\n",
      "dj_dw1_before -1.6794734165159753e-05\n",
      "dj_dw1_after -1.8815917883330258e-05\n",
      "dj_dw1: -1.8815917883330258e-05\n",
      "dj_dw2_before -5.6417754876747495e-06\n",
      "dj_dw2_after -6.652367346760002e-06\n",
      "dj_dw2: -6.652367346760002e-06\n",
      "dj_dw3_before -0.00017235030213669233\n",
      "dj_dw3_after -0.00020772101720467617\n",
      "dj_dw3: -0.00020772101720467617\n",
      "dj_db2_before -4.011183591501322e-06\n",
      "dj_db2_after -5.021775450586574e-06\n",
      "\n",
      "dj_db -6.695700600782099e-06\n",
      "dj_dw [-1.09049431e-02 -2.50878905e-05 -8.86982313e-06 -2.76961356e-04]\n"
     ]
    }
   ],
   "source": [
    "tmp_dj_db, tmp_dj_dw = compute_gradient(x_train, y_train, w_init, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "   \n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251501955248e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.72623577e-03 -6.27197263e-06 -2.21745578e-06 -6.92403391e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(x_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,y,w_in,b_in,cost_function,gradient_function,alpha,num_iters):\n",
    "    J_history = []\n",
    "    w=copy.deepcopy(w_in)\n",
    "    b=b_in\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw,dj_db=gradient_function(x,y,w,b)\n",
    "\n",
    "        w=w-alpha*dj_dw\n",
    "        b=b-alpha*dj_db\n",
    "\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(x,y,w,b))\n",
    "\n",
    "        if i%math.ceil(num_iters/10) == 0:\n",
    "            print(f'Iteration {i:4d}: Cost {J_history[-1]:8.2f}')\n",
    "    return w,b,J_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2104,    5,    1,   45],\n",
       "       [1416,    3,    2,   40],\n",
       "       [ 852,    2,    1,   35]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      4\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0e-7\u001b[39m\n\u001b[0;32m----> 5\u001b[0m w_final, b_final, J_hist \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43minitial_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43minitial_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mcompute_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,w found by gradient descent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_final\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw_final\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m m,_ \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[70], line 16\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters)\u001b[0m\n\u001b[1;32m     13\u001b[0m         J_history\u001b[38;5;241m.\u001b[39mappend(cost_function(x,y,w,b))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil(num_iters\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Cost \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mJ_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m8.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m w,b,J_history\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "w_final, b_final, J_hist = gradient_descent(x_train, y_train,initial_w,initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = x_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(x_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
